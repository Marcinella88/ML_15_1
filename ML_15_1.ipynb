{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638216cb",
   "metadata": {},
   "source": [
    "**Import bibliotek:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c36bc8",
   "metadata": {},
   "source": [
    "**Import bazy danych:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93782d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fba767",
   "metadata": {},
   "source": [
    "**Podział danych na zmienne objaśniające (X) i objaśniane (y):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.drop(['Diabetic'], axis=1).copy()\n",
    "y = diabetes['Diabetic'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b42a7",
   "metadata": {},
   "source": [
    "**Towrzymy grupę danych numerycznych - num_features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure', 'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca7726",
   "metadata": {},
   "source": [
    "**Tworzenie pipeline zawierającego różne 'preprocessory' danych:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preparation = Pipeline(steps=[\n",
    "                                ('fill_missing', SimpleImputer(strategy='median')),\n",
    "                                ('polynomial_features', PolynomialFeatures(degree=3)),\n",
    "                                ('scaler_1', StandardScaler()),\n",
    "                                ('pca', PCA(n_components=0.95)),\n",
    "                                ('scaler_2', StandardScaler())\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b3c45e",
   "metadata": {},
   "source": [
    "**Tworzenie transformatora danych w kolumnach - data_preparation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparation = ColumnTransformer(transformers=[('numeric_preprocessing', num_preparation, num_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa65dd9",
   "metadata": {},
   "source": [
    "**Tworzymy pipeline zawierający - transormator danych w kolumnach i model ML - LogisticRegression:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline_v1 = Pipeline(steps=[\n",
    "                                ('preprocessor',data_preparation),\n",
    "                                ('model', LogisticRegression(max_iter=10000))\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fadb0b",
   "metadata": {},
   "source": [
    "**Trenujemy model - model_pipeline_v1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline_v1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea3edc4",
   "metadata": {},
   "source": [
    "**Tworzymy funkcję calculate_metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab54c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dataframe = pd.DataFrame(columns = ['Model', 'F1_score', 'AUC'])\n",
    "metrics_dataframe\n",
    "models = []\n",
    "models_names = []\n",
    "predictions_proba_list = []\n",
    "\n",
    "def calculate_metrics(model, name, X_checked, y_checked):\n",
    "    models.append(model)\n",
    "    models_names.append(name)\n",
    "    global metrics_dataframe\n",
    "    predictions = model.predict(X_checked)\n",
    "    predictions_proba = model.predict_proba(X_checked)\n",
    "    predictions_proba_list.append(predictions_proba[:,1])\n",
    "\n",
    "    f1_metric = f1_score(y_checked, predictions)\n",
    "    auc_metric = roc_auc_score(y_checked, predictions_proba[:,1])\n",
    "    new_row = pd.DataFrame([{'Model': name, 'F1_score': f1_metric, 'AUC': auc_metric}])\n",
    "    metrics_dataframe = pd.concat([metrics_dataframe, new_row], ignore_index=True)\n",
    "    return metrics_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67db81f",
   "metadata": {},
   "source": [
    "**Uruchamiamy funkcję calculate_metrics dla modelu: model_pipeline_v1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3579df",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(model_pipeline_v1, 'Logistic Regression - pipeline', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dfb62c",
   "metadata": {},
   "source": [
    "**Tworzymy nowy podział danych treningowych i testowych:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f785d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[['Pregnancies', 'Age']], y, test_size=0.30, random_state=0, stratify=y)\n",
    "\n",
    "scaler_2var = StandardScaler()\n",
    "X_train_standardized = scaler_2var.fit_transform(X_train)\n",
    "X_test_standardized = scaler_2var.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e70d5",
   "metadata": {},
   "source": [
    "**Tworzymy funkcję generate_model_LR:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8414a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=[]\n",
    "\n",
    "def generate_model_LR(penalty,C):\n",
    "    global model_list\n",
    "    \n",
    "    if penalty==\"l1\":\n",
    "        model = LogisticRegression(penalty=penalty,C=C,solver='liblinear')\n",
    "    elif penalty==\"l2\":\n",
    "        model = LogisticRegression(penalty=penalty,C=C)\n",
    "    elif penalty==\"elasticnet\":\n",
    "        model = LogisticRegression(penalty=penalty,C=C,solver='saga', l1_ratio=0.1)\n",
    "    else:\n",
    "        raise ValueError(\"Nieprawidłowa wartość 'penalty'\")\n",
    "    \n",
    "    name = f\"LogisticRegression_penalty:{penalty},C:{C}\"\n",
    "    model_list.append((model, name))\n",
    "    return model, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e57c5f",
   "metadata": {},
   "source": [
    "**Tworzymy zbiory parametrów: penalties oraz parametr C oraz generujemy modele funkcją generate_model_LR:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = ['l1','l2','elasticnet']\n",
    "parametrs_C = [0.01,0.1,1,10,100]\n",
    "\n",
    "for penalty in penalties:\n",
    "    for C in parametrs_C:\n",
    "      generate_model_LR(penalty,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad881a",
   "metadata": {},
   "source": [
    "**Trenujemy w/w modele:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b3a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in model_list:\n",
    "    model.fit(X_train_standardized,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd3275d",
   "metadata": {},
   "source": [
    "**Uruchamiamy funkcję calculate_metrics dla nowo wygenerownych modeli:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in model_list:\n",
    "    metrics_dataframe = calculate_metrics(model, name, X_test_standardized, y_test)\n",
    "\n",
    "display(metrics_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e1441",
   "metadata": {},
   "source": [
    "**Wnioski:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b589e",
   "metadata": {},
   "source": [
    "Wygenerowany pipeline uzyskał lepszy parametr F1, ponadto automatyzuje czynności takie jak uzupełnianie braków danych przez wprowadzenie wartości równej medianie dla zbioru treningowego dla wartości numerycznych. Ponadto pipeline zawiera w odróżnieniu do później wygenerowanych modeli funkcję wielomianu stopnia 3 oraz funkcję PCA, być może dlatego uzyskuje lepszy rezultat dla danych testowych. Być może pipeline ma lepsze wyniki różnież ze względu na różnice w parametrze max_iter - dla pipeline jest to 10000 a dla pozostałych modeli to domyślna wartość: 100."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
